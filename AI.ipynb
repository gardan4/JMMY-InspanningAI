{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin hier\n",
    "Begin met het runnen van deze blokken code.  \n",
    "Deze zijn verantwoordelijk voor imports, setup, dependencies en andere zaken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15288756271378782890\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5738397696\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12573432263527696316\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "2.8.0\n",
      "True\n",
      "Succes loading Imports\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import data_generator as dgen\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, Input, Concatenate, Lambda\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "print(tf.__version__)\n",
    "print(len(tf.config.list_physical_devices('GPU'))>0)\n",
    "\n",
    "print(\"Succes loading Imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succes loading Functions\n"
     ]
    }
   ],
   "source": [
    "# Functions\n",
    "def get_file_name(path):\n",
    "    file_name = path[path.rfind('/') + 1:]\n",
    "    # Splits out the file-type designation\n",
    "    file_name, file_extension = file_name.split('.')\n",
    "    return file_name\n",
    "    \n",
    "print(\"Succes loading Functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heb je al data?\n",
    "Als er al trainingsdata bestaat, schrijf dan simpelweg de filename bij het betreffende blok.  \n",
    "Run anders het blok waarin de data nog word gegenereerd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Ik heb geen data\"\"\"\n",
    "# Start here if no data has been generated.\n",
    "\n",
    "print(\"Provide the path to a video file.\\n\"\n",
    "      \"  (Example: C:/Users/admin/video/video.mp4)\")\n",
    "\n",
    "vid_path = input(\"Provide a video path: \")\n",
    "vid_name = get_file_name(vid_path)\n",
    "print(f\"Provided path: '{vid_path}',\\nfound filename: '{vid_name}'\")\n",
    "print(\"\")\n",
    "\n",
    "generator = dgen.Generator(vid_path)\n",
    "generator.generate_data()\n",
    "print(f\"Video has been processed and exported to {generator.file_name}__trainingsData.mp4\")\n",
    "print(f\"Data generated and exported to {generator.file_name}_trainingsData.json\")\n",
    "print(\"\")\n",
    "\n",
    "try: \n",
    "      data_path = f\"generateData_OUTPUT/{vid_name}_trainingsData.json\"\n",
    "      frame_data = pd.read_json(data_path, orient='index')\n",
    "except Exception as e:\n",
    "      print(f\"Something went wrong.\\n {e}\")\n",
    "\n",
    "\n",
    "print(\"The data-table was loaded. \\nTotal Table size: \")\n",
    "print(f\"Rows: {frame_data.shape[0]}, Columns: {frame_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide the filename to a file in the generateData_OUTPUT folder.\n",
      "Example: perfect_example_trainingsData\n",
      "Provided path: generateData_OUTPUT/GOPR1124_Trim_trainingsData.json\n",
      "\n",
      "Total Table size: \n",
      "Rows: 18646, Columns: 482\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Ik heb al trainingsdata. \"\"\"\n",
    "# Start here if data has already been generated.\n",
    "print(\"Provide the filename to a file in \"\n",
    "      \"the generateData_OUTPUT folder.\\n\"\n",
    "      \"Example: perfect_example_trainingsData\")\n",
    "      \n",
    "data_path = input(\"Filename: \")\n",
    "vid_name = get_file_name(data_path)\n",
    "print(f\"Provided path: {data_path}\")\n",
    "\n",
    "try: \n",
    "      data_path = f\"generateData_OUTPUT/{vid_name}.json\"\n",
    "      frame_data = pd.read_json(data_path, orient='index')\n",
    "except Exception as e:\n",
    "      print(f\"Something went wrong.\\n {e}\")\n",
    "\n",
    "print(\"\\nTotal Table size: \")\n",
    "print(f\"Rows: {frame_data.shape[0]}, Columns: {frame_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "    TS  HR  PWR  heartRateZone  \\\n1  505  85   50              0   \n2  505  85   50              0   \n3  505  85   50              0   \n4  505  85   50              0   \n5  505  85   50              0   \n\n                                                   0  \\\n1  [[0.557644486427307, 0.648186445236206, -0.040...   \n2  [[0.557781159877777, 0.652138113975524, -0.040...   \n3  [[0.5626065135002131, 0.656960010528564, -0.04...   \n4  [[0.561814308166503, 0.6575654745101921, -0.04...   \n5  [[0.5678303241729731, 0.663326919078826, -0.03...   \n\n                                                   1  \\\n1  [[0.557483077049255, 0.552068829536438, -0.076...   \n2  [[0.5576397776603691, 0.555081248283386, -0.07...   \n3  [[0.5579067468643181, 0.556771099567413, -0.07...   \n4  [[0.559345841407775, 0.5556150674819941, -0.07...   \n5  [[0.5601344108581541, 0.554888725280761, -0.07...   \n\n                                                   2  \\\n1  [[0.553551793098449, 0.5780954957008361, -0.04...   \n2  [[0.5538336634635921, 0.5809364914894101, -0.0...   \n3  [[0.554864883422851, 0.582704246044158, -0.041...   \n4  [[0.555837929248809, 0.58216106891632, -0.0412...   \n5  [[0.556598603725433, 0.581692636013031, -0.040...   \n\n                                                   3  \\\n1  [[0.54665207862854, 0.46006208658218306, -0.05...   \n2  [[0.547837734222412, 0.46182113885879505, -0.0...   \n3  [[0.5476696491241451, 0.463245302438735, -0.05...   \n4  [[0.548979759216308, 0.46244707703590304, -0.0...   \n5  [[0.5491563081741331, 0.460878789424896, -0.05...   \n\n                                                   4  \\\n1  [[0.558870553970336, 0.5247067213058471, -0.08...   \n2  [[0.5592626929283141, 0.527342796325683, -0.08...   \n3  [[0.559209465980529, 0.528769314289093, -0.080...   \n4  [[0.560742497444152, 0.527681291103363, -0.080...   \n5  [[0.5613942146301271, 0.526626706123352, -0.08...   \n\n                                                   5  ...  \\\n1  [[0.559488832950592, 0.48826456069946206, -0.0...  ...   \n2  [[0.56026405096054, 0.490500211715698, -0.0747...  ...   \n3  [[0.560060918331146, 0.49175029993057207, -0.0...  ...   \n4  [[0.5615682601928711, 0.490862190723419, -0.07...  ...   \n5  [[0.561959207057952, 0.489454329013824, -0.074...  ...   \n\n                                                 468  \\\n1  [[0.480815052986145, 0.37191823124885504, 0.00...   \n2  [[0.48186632990837003, 0.372595608234405, 0.00...   \n3  [[0.482597649097442, 0.37554320693016, 0.00381...   \n4  [[0.48320049047470004, 0.37472867965698203, 0....   \n5  [[0.48083800077438305, 0.37290006875991805, 0....   \n\n                                                 469  \\\n1  [[0.49536809325218206, 0.371358275413513, 0.00...   \n2  [[0.496729910373687, 0.37259367108345004, 0.00...   \n3  [[0.49783867597579906, 0.37549942731857305, 0....   \n4  [[0.49830114841461104, 0.37439942359924305, 0....   \n5  [[0.495698124170303, 0.372656464576721, 0.0036...   \n\n                                                 470  \\\n1  [[0.480778813362121, 0.34924191236495905, 0.00...   \n2  [[0.48208233714103704, 0.349857658147811, 0.00...   \n3  [[0.482793241739273, 0.35240229964256203, 0.00...   \n4  [[0.48332807421684204, 0.35114678740501404, 0....   \n5  [[0.48110470175743103, 0.348926812410354, 0.00...   \n\n                                                 471  \\\n1  [[0.46612980961799605, 0.37237301468849104, 0....   \n2  [[0.466910362243652, 0.37237179279327304, 0.00...   \n3  [[0.46731585264205905, 0.37538290023803705, 0....   \n4  [[0.46801066398620605, 0.37484848499298, 0.005...   \n5  [[0.46586400270462003, 0.37290182709693903, 0....   \n\n                                                 472  \\\n1  [[0.48077648878097506, 0.39444035291671703, 0....   \n2  [[0.481569498777389, 0.39509481191635104, 0.00...   \n3  [[0.48236334323883, 0.39839088916778503, 0.003...   \n4  [[0.48302134871482805, 0.39804667234420704, 0....   \n5  [[0.480530679225921, 0.396575450897216, 0.0036...   \n\n                                                 473  \\\n1  [[0.619437217712402, 0.38546937704086304, 0.02...   \n2  [[0.619723141193389, 0.38572886586189203, 0.02...   \n3  [[0.6212606430053711, 0.387251198291778, 0.020...   \n4  [[0.621431291103363, 0.387765794992446, 0.0204...   \n5  [[0.620188117027282, 0.38609468936920105, 0.02...   \n\n                                                 474  \\\n1  [[0.6340233087539671, 0.388074874877929, 0.021...   \n2  [[0.6348772048950191, 0.38816174864768904, 0.0...   \n3  [[0.635286450386047, 0.39012062549591003, 0.02...   \n4  [[0.635533690452575, 0.39082396030426003, 0.02...   \n5  [[0.634687542915344, 0.389000535011291, 0.0203...   \n\n                                                 475  \\\n1  [[0.620652437210083, 0.36350065469741805, 0.02...   \n2  [[0.620543837547302, 0.363969087600708, 0.0203...   \n3  [[0.6227678656578061, 0.365785002708435, 0.020...   \n4  [[0.62286365032196, 0.366147100925445, 0.02042...   \n5  [[0.621634900569915, 0.36374190449714605, 0.02...   \n\n                                                 476  \\\n1  [[0.6047459840774531, 0.38255375623703003, 0.0...   \n2  [[0.6045479774475091, 0.38323295116424505, 0.0...   \n3  [[0.607255220413208, 0.38423293828964206, 0.02...   \n4  [[0.60738605260849, 0.38455718755722, 0.020420...   \n5  [[0.605783760547637, 0.38302057981491006, 0.02...   \n\n                                                 477  \n1  [[0.6183456778526301, 0.40718841552734303, 0.0...  \n2  [[0.6189938783645631, 0.40755006670951804, 0.0...  \n3  [[0.619867324829101, 0.40856561064720104, 0.02...  \n4  [[0.620088934898376, 0.40927729010581904, 0.02...  \n5  [[0.6188414692878721, 0.408338665962219, 0.020...  \n\n[5 rows x 482 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TS</th>\n      <th>HR</th>\n      <th>PWR</th>\n      <th>heartRateZone</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>...</th>\n      <th>468</th>\n      <th>469</th>\n      <th>470</th>\n      <th>471</th>\n      <th>472</th>\n      <th>473</th>\n      <th>474</th>\n      <th>475</th>\n      <th>476</th>\n      <th>477</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>505</td>\n      <td>85</td>\n      <td>50</td>\n      <td>0</td>\n      <td>[[0.557644486427307, 0.648186445236206, -0.040...</td>\n      <td>[[0.557483077049255, 0.552068829536438, -0.076...</td>\n      <td>[[0.553551793098449, 0.5780954957008361, -0.04...</td>\n      <td>[[0.54665207862854, 0.46006208658218306, -0.05...</td>\n      <td>[[0.558870553970336, 0.5247067213058471, -0.08...</td>\n      <td>[[0.559488832950592, 0.48826456069946206, -0.0...</td>\n      <td>...</td>\n      <td>[[0.480815052986145, 0.37191823124885504, 0.00...</td>\n      <td>[[0.49536809325218206, 0.371358275413513, 0.00...</td>\n      <td>[[0.480778813362121, 0.34924191236495905, 0.00...</td>\n      <td>[[0.46612980961799605, 0.37237301468849104, 0....</td>\n      <td>[[0.48077648878097506, 0.39444035291671703, 0....</td>\n      <td>[[0.619437217712402, 0.38546937704086304, 0.02...</td>\n      <td>[[0.6340233087539671, 0.388074874877929, 0.021...</td>\n      <td>[[0.620652437210083, 0.36350065469741805, 0.02...</td>\n      <td>[[0.6047459840774531, 0.38255375623703003, 0.0...</td>\n      <td>[[0.6183456778526301, 0.40718841552734303, 0.0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>505</td>\n      <td>85</td>\n      <td>50</td>\n      <td>0</td>\n      <td>[[0.557781159877777, 0.652138113975524, -0.040...</td>\n      <td>[[0.5576397776603691, 0.555081248283386, -0.07...</td>\n      <td>[[0.5538336634635921, 0.5809364914894101, -0.0...</td>\n      <td>[[0.547837734222412, 0.46182113885879505, -0.0...</td>\n      <td>[[0.5592626929283141, 0.527342796325683, -0.08...</td>\n      <td>[[0.56026405096054, 0.490500211715698, -0.0747...</td>\n      <td>...</td>\n      <td>[[0.48186632990837003, 0.372595608234405, 0.00...</td>\n      <td>[[0.496729910373687, 0.37259367108345004, 0.00...</td>\n      <td>[[0.48208233714103704, 0.349857658147811, 0.00...</td>\n      <td>[[0.466910362243652, 0.37237179279327304, 0.00...</td>\n      <td>[[0.481569498777389, 0.39509481191635104, 0.00...</td>\n      <td>[[0.619723141193389, 0.38572886586189203, 0.02...</td>\n      <td>[[0.6348772048950191, 0.38816174864768904, 0.0...</td>\n      <td>[[0.620543837547302, 0.363969087600708, 0.0203...</td>\n      <td>[[0.6045479774475091, 0.38323295116424505, 0.0...</td>\n      <td>[[0.6189938783645631, 0.40755006670951804, 0.0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>505</td>\n      <td>85</td>\n      <td>50</td>\n      <td>0</td>\n      <td>[[0.5626065135002131, 0.656960010528564, -0.04...</td>\n      <td>[[0.5579067468643181, 0.556771099567413, -0.07...</td>\n      <td>[[0.554864883422851, 0.582704246044158, -0.041...</td>\n      <td>[[0.5476696491241451, 0.463245302438735, -0.05...</td>\n      <td>[[0.559209465980529, 0.528769314289093, -0.080...</td>\n      <td>[[0.560060918331146, 0.49175029993057207, -0.0...</td>\n      <td>...</td>\n      <td>[[0.482597649097442, 0.37554320693016, 0.00381...</td>\n      <td>[[0.49783867597579906, 0.37549942731857305, 0....</td>\n      <td>[[0.482793241739273, 0.35240229964256203, 0.00...</td>\n      <td>[[0.46731585264205905, 0.37538290023803705, 0....</td>\n      <td>[[0.48236334323883, 0.39839088916778503, 0.003...</td>\n      <td>[[0.6212606430053711, 0.387251198291778, 0.020...</td>\n      <td>[[0.635286450386047, 0.39012062549591003, 0.02...</td>\n      <td>[[0.6227678656578061, 0.365785002708435, 0.020...</td>\n      <td>[[0.607255220413208, 0.38423293828964206, 0.02...</td>\n      <td>[[0.619867324829101, 0.40856561064720104, 0.02...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>505</td>\n      <td>85</td>\n      <td>50</td>\n      <td>0</td>\n      <td>[[0.561814308166503, 0.6575654745101921, -0.04...</td>\n      <td>[[0.559345841407775, 0.5556150674819941, -0.07...</td>\n      <td>[[0.555837929248809, 0.58216106891632, -0.0412...</td>\n      <td>[[0.548979759216308, 0.46244707703590304, -0.0...</td>\n      <td>[[0.560742497444152, 0.527681291103363, -0.080...</td>\n      <td>[[0.5615682601928711, 0.490862190723419, -0.07...</td>\n      <td>...</td>\n      <td>[[0.48320049047470004, 0.37472867965698203, 0....</td>\n      <td>[[0.49830114841461104, 0.37439942359924305, 0....</td>\n      <td>[[0.48332807421684204, 0.35114678740501404, 0....</td>\n      <td>[[0.46801066398620605, 0.37484848499298, 0.005...</td>\n      <td>[[0.48302134871482805, 0.39804667234420704, 0....</td>\n      <td>[[0.621431291103363, 0.387765794992446, 0.0204...</td>\n      <td>[[0.635533690452575, 0.39082396030426003, 0.02...</td>\n      <td>[[0.62286365032196, 0.366147100925445, 0.02042...</td>\n      <td>[[0.60738605260849, 0.38455718755722, 0.020420...</td>\n      <td>[[0.620088934898376, 0.40927729010581904, 0.02...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>505</td>\n      <td>85</td>\n      <td>50</td>\n      <td>0</td>\n      <td>[[0.5678303241729731, 0.663326919078826, -0.03...</td>\n      <td>[[0.5601344108581541, 0.554888725280761, -0.07...</td>\n      <td>[[0.556598603725433, 0.581692636013031, -0.040...</td>\n      <td>[[0.5491563081741331, 0.460878789424896, -0.05...</td>\n      <td>[[0.5613942146301271, 0.526626706123352, -0.08...</td>\n      <td>[[0.561959207057952, 0.489454329013824, -0.074...</td>\n      <td>...</td>\n      <td>[[0.48083800077438305, 0.37290006875991805, 0....</td>\n      <td>[[0.495698124170303, 0.372656464576721, 0.0036...</td>\n      <td>[[0.48110470175743103, 0.348926812410354, 0.00...</td>\n      <td>[[0.46586400270462003, 0.37290182709693903, 0....</td>\n      <td>[[0.480530679225921, 0.396575450897216, 0.0036...</td>\n      <td>[[0.620188117027282, 0.38609468936920105, 0.02...</td>\n      <td>[[0.634687542915344, 0.389000535011291, 0.0203...</td>\n      <td>[[0.621634900569915, 0.36374190449714605, 0.02...</td>\n      <td>[[0.605783760547637, 0.38302057981491006, 0.02...</td>\n      <td>[[0.6188414692878721, 0.408338665962219, 0.020...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 482 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "Xtemp = frame_data.drop(columns=['TS', 'HR', 'PWR', 'heartRateZone'])\n",
    "Y = frame_data[\"heartRateZone\"]\n",
    "X = []\n",
    "temp = []\n",
    "\n",
    "\n",
    "\n",
    "for index, row in Xtemp.iterrows():\n",
    "    for i in range(0,478):\n",
    "        for g in range(0,3):\n",
    "            temp.append(row[i][0][g])\n",
    "    X.append(temp)\n",
    "    temp = []\n",
    "Y.to_numpy()\n",
    "Y = Y.values.reshape(-1,1)\n",
    "temps = np.zeros((len(Y), 6))\n",
    "\n",
    "for i in range(0,len(Y)):\n",
    "    if Y[i][0] == 0:\n",
    "        temps[i][0] = 1\n",
    "    elif Y[i][0] == 1:\n",
    "        temps[i][1] = 1\n",
    "    elif Y[i][0] == 2:\n",
    "        temps[i][2] = 1\n",
    "    elif Y[i][0] == 3:\n",
    "        temps[i][3] = 1\n",
    "    elif Y[i][0] == 4:\n",
    "        temps[i][4] = 1\n",
    "    elif Y[i][0] == 5:\n",
    "        temps[i][5] = 1\n",
    "\n",
    "print(temps)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#tf.debugging.set_log_device_placement(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12492, 1434)\n",
      "(12492, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, temps, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "inputTensor = Input(shape=(1434,))\n",
    "layers = []\n",
    "\n",
    "for i in range(0, 1434, 3):\n",
    "    layers.append(Lambda(lambda x: x[:,i: i+3], output_shape=((3,)))(inputTensor))\n",
    "for i in range(0, 478):\n",
    "    layers[i] = Dense(1)(layers[i])\n",
    "coordslayer = Concatenate()(layers)\n",
    "\n",
    "hidden1 = Dense(477*2, activation='relu')(coordslayer)\n",
    "hidden2 = Dense(477, activation='relu')(hidden1)\n",
    "hidden3 = Dense(240, activation='relu')(hidden2)\n",
    "hidden4 = Dense(100, activation='relu')(hidden3)\n",
    "hidden5 = Dense(20, activation='relu')(hidden4)\n",
    "\n",
    "outputTensor = Dense(6, activation='sigmoid')(hidden5)\n",
    "model = Model(inputs=inputTensor, outputs=outputTensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "125/125 [==============================] - 25s 98ms/step - loss: 1.1200 - accuracy: 0.5309\n",
      "Epoch 2/150\n",
      "125/125 [==============================] - 12s 93ms/step - loss: 0.9368 - accuracy: 0.5857\n",
      "Epoch 3/150\n",
      "125/125 [==============================] - 12s 93ms/step - loss: 0.8992 - accuracy: 0.6028\n",
      "Epoch 4/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.8863 - accuracy: 0.6046\n",
      "Epoch 5/150\n",
      "125/125 [==============================] - 14s 108ms/step - loss: 0.8761 - accuracy: 0.6102\n",
      "Epoch 6/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.8851 - accuracy: 0.6118\n",
      "Epoch 7/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.8719 - accuracy: 0.6141\n",
      "Epoch 8/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.8616 - accuracy: 0.6181\n",
      "Epoch 9/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.8696 - accuracy: 0.6171\n",
      "Epoch 10/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.8618 - accuracy: 0.6173\n",
      "Epoch 11/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.8576 - accuracy: 0.6168\n",
      "Epoch 12/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.8539 - accuracy: 0.6170\n",
      "Epoch 13/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.8419 - accuracy: 0.6268\n",
      "Epoch 14/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.8308 - accuracy: 0.6282\n",
      "Epoch 15/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.8377 - accuracy: 0.6222\n",
      "Epoch 16/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.8304 - accuracy: 0.6269\n",
      "Epoch 17/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.8234 - accuracy: 0.6291\n",
      "Epoch 18/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.8229 - accuracy: 0.6342\n",
      "Epoch 19/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.8222 - accuracy: 0.6315\n",
      "Epoch 20/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.8148 - accuracy: 0.6435\n",
      "Epoch 21/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.8066 - accuracy: 0.6435\n",
      "Epoch 22/150\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.8047 - accuracy: 0.6431\n",
      "Epoch 23/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.7946 - accuracy: 0.6466\n",
      "Epoch 24/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.7941 - accuracy: 0.6476\n",
      "Epoch 25/150\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.7948 - accuracy: 0.6475\n",
      "Epoch 26/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7820 - accuracy: 0.6580\n",
      "Epoch 27/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7876 - accuracy: 0.6532\n",
      "Epoch 28/150\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.7781 - accuracy: 0.6554\n",
      "Epoch 29/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7782 - accuracy: 0.6622\n",
      "Epoch 30/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7704 - accuracy: 0.6587\n",
      "Epoch 31/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7651 - accuracy: 0.6627\n",
      "Epoch 32/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.7667 - accuracy: 0.6634\n",
      "Epoch 33/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.7644 - accuracy: 0.6609\n",
      "Epoch 34/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.7622 - accuracy: 0.6675\n",
      "Epoch 35/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.7586 - accuracy: 0.6669\n",
      "Epoch 36/150\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.7609 - accuracy: 0.6629\n",
      "Epoch 37/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7636 - accuracy: 0.6608\n",
      "Epoch 38/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7610 - accuracy: 0.6641\n",
      "Epoch 39/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.7496 - accuracy: 0.6680\n",
      "Epoch 40/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.7536 - accuracy: 0.6661\n",
      "Epoch 41/150\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.7565 - accuracy: 0.6634\n",
      "Epoch 42/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.7560 - accuracy: 0.6657\n",
      "Epoch 43/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.7450 - accuracy: 0.6724\n",
      "Epoch 44/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7457 - accuracy: 0.6711\n",
      "Epoch 45/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7517 - accuracy: 0.6676\n",
      "Epoch 46/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7468 - accuracy: 0.6704\n",
      "Epoch 47/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7472 - accuracy: 0.6687\n",
      "Epoch 48/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.7459 - accuracy: 0.6707\n",
      "Epoch 49/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.7465 - accuracy: 0.6666\n",
      "Epoch 50/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.7472 - accuracy: 0.6713\n",
      "Epoch 51/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.7419 - accuracy: 0.6728\n",
      "Epoch 52/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.7424 - accuracy: 0.6707\n",
      "Epoch 53/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7399 - accuracy: 0.6731\n",
      "Epoch 54/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.7387 - accuracy: 0.6732\n",
      "Epoch 55/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.7366 - accuracy: 0.6721\n",
      "Epoch 56/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.7335 - accuracy: 0.6756\n",
      "Epoch 57/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.7376 - accuracy: 0.6748\n",
      "Epoch 58/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7402 - accuracy: 0.6734\n",
      "Epoch 59/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.7339 - accuracy: 0.6771\n",
      "Epoch 60/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.7319 - accuracy: 0.6764\n",
      "Epoch 61/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7304 - accuracy: 0.6798\n",
      "Epoch 62/150\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.7274 - accuracy: 0.6786\n",
      "Epoch 63/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.7305 - accuracy: 0.6820\n",
      "Epoch 64/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.7347 - accuracy: 0.6744\n",
      "Epoch 65/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.7290 - accuracy: 0.6788\n",
      "Epoch 66/150\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.7246 - accuracy: 0.6798\n",
      "Epoch 67/150\n",
      "125/125 [==============================] - 12s 93ms/step - loss: 0.7316 - accuracy: 0.6801\n",
      "Epoch 68/150\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.7263 - accuracy: 0.6794\n",
      "Epoch 69/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.7259 - accuracy: 0.6838\n",
      "Epoch 70/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.7274 - accuracy: 0.6810\n",
      "Epoch 71/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.7200 - accuracy: 0.6828\n",
      "Epoch 72/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7240 - accuracy: 0.6821\n",
      "Epoch 73/150\n",
      "125/125 [==============================] - 12s 93ms/step - loss: 0.7195 - accuracy: 0.6849\n",
      "Epoch 74/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.7203 - accuracy: 0.6841\n",
      "Epoch 75/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.7188 - accuracy: 0.6849\n",
      "Epoch 76/150\n",
      "125/125 [==============================] - 12s 94ms/step - loss: 0.7136 - accuracy: 0.6871\n",
      "Epoch 77/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7158 - accuracy: 0.6865\n",
      "Epoch 78/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.7193 - accuracy: 0.6868\n",
      "Epoch 79/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.7177 - accuracy: 0.6855\n",
      "Epoch 80/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7212 - accuracy: 0.6856\n",
      "Epoch 81/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.7143 - accuracy: 0.6867\n",
      "Epoch 82/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7185 - accuracy: 0.6833\n",
      "Epoch 83/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7100 - accuracy: 0.6887\n",
      "Epoch 84/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.7251 - accuracy: 0.6819\n",
      "Epoch 85/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.7244 - accuracy: 0.6840\n",
      "Epoch 86/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.7107 - accuracy: 0.6913\n",
      "Epoch 87/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.7184 - accuracy: 0.6870\n",
      "Epoch 88/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.7140 - accuracy: 0.6883\n",
      "Epoch 89/150\n",
      "125/125 [==============================] - 12s 95ms/step - loss: 0.7077 - accuracy: 0.6938\n",
      "Epoch 90/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7105 - accuracy: 0.6901\n",
      "Epoch 91/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.7083 - accuracy: 0.6937\n",
      "Epoch 92/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.7045 - accuracy: 0.6969\n",
      "Epoch 93/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.7058 - accuracy: 0.6920\n",
      "Epoch 94/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7094 - accuracy: 0.6940\n",
      "Epoch 95/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.7120 - accuracy: 0.6933\n",
      "Epoch 96/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.6986 - accuracy: 0.6971\n",
      "Epoch 97/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.7002 - accuracy: 0.6969\n",
      "Epoch 98/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.7013 - accuracy: 0.6952\n",
      "Epoch 99/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6929 - accuracy: 0.7001\n",
      "Epoch 100/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6930 - accuracy: 0.6993\n",
      "Epoch 101/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6966 - accuracy: 0.6972\n",
      "Epoch 102/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.6933 - accuracy: 0.6975\n",
      "Epoch 103/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6869 - accuracy: 0.7037\n",
      "Epoch 104/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6894 - accuracy: 0.7042\n",
      "Epoch 105/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6905 - accuracy: 0.7021\n",
      "Epoch 106/150\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.6875 - accuracy: 0.7025\n",
      "Epoch 107/150\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.6847 - accuracy: 0.7074\n",
      "Epoch 108/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6790 - accuracy: 0.7074\n",
      "Epoch 109/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6730 - accuracy: 0.7114\n",
      "Epoch 110/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6724 - accuracy: 0.7120\n",
      "Epoch 111/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6765 - accuracy: 0.7087\n",
      "Epoch 112/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6745 - accuracy: 0.7103\n",
      "Epoch 113/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6691 - accuracy: 0.7112\n",
      "Epoch 114/150\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.6587 - accuracy: 0.7163\n",
      "Epoch 115/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6629 - accuracy: 0.7165\n",
      "Epoch 116/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6604 - accuracy: 0.7165\n",
      "Epoch 117/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6563 - accuracy: 0.7217\n",
      "Epoch 118/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6625 - accuracy: 0.7198\n",
      "Epoch 119/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.6558 - accuracy: 0.7218\n",
      "Epoch 120/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.6597 - accuracy: 0.7181\n",
      "Epoch 121/150\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.6505 - accuracy: 0.7229\n",
      "Epoch 122/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6574 - accuracy: 0.7217\n",
      "Epoch 123/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6531 - accuracy: 0.7213\n",
      "Epoch 124/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6510 - accuracy: 0.7213\n",
      "Epoch 125/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6422 - accuracy: 0.7258\n",
      "Epoch 126/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6414 - accuracy: 0.7270\n",
      "Epoch 127/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6482 - accuracy: 0.7255\n",
      "Epoch 128/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6469 - accuracy: 0.7248\n",
      "Epoch 129/150\n",
      "125/125 [==============================] - 13s 107ms/step - loss: 0.6423 - accuracy: 0.7245\n",
      "Epoch 130/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6403 - accuracy: 0.7248\n",
      "Epoch 131/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.6445 - accuracy: 0.7253\n",
      "Epoch 132/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6374 - accuracy: 0.7269\n",
      "Epoch 133/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.6464 - accuracy: 0.7239\n",
      "Epoch 134/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6463 - accuracy: 0.7239\n",
      "Epoch 135/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.6400 - accuracy: 0.7272\n",
      "Epoch 136/150\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.6364 - accuracy: 0.7321\n",
      "Epoch 137/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6438 - accuracy: 0.7241\n",
      "Epoch 138/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.6442 - accuracy: 0.7231\n",
      "Epoch 139/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.6325 - accuracy: 0.7305\n",
      "Epoch 140/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6348 - accuracy: 0.7302\n",
      "Epoch 141/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6257 - accuracy: 0.7324\n",
      "Epoch 142/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.6260 - accuracy: 0.7336\n",
      "Epoch 143/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6379 - accuracy: 0.7244\n",
      "Epoch 144/150\n",
      "125/125 [==============================] - 13s 106ms/step - loss: 0.6297 - accuracy: 0.7286\n",
      "Epoch 145/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6269 - accuracy: 0.7315\n",
      "Epoch 146/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6310 - accuracy: 0.7303\n",
      "Epoch 147/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6280 - accuracy: 0.7314\n",
      "Epoch 148/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6236 - accuracy: 0.7353\n",
      "Epoch 149/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6260 - accuracy: 0.7329\n",
      "Epoch 150/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6273 - accuracy: 0.7317\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x19694446380>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.6258 - accuracy: 0.7290\n",
      "Epoch 2/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6269 - accuracy: 0.7327\n",
      "Epoch 3/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.6225 - accuracy: 0.7362\n",
      "Epoch 4/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6246 - accuracy: 0.7320\n",
      "Epoch 5/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6211 - accuracy: 0.7331\n",
      "Epoch 6/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.6241 - accuracy: 0.7311\n",
      "Epoch 7/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.6203 - accuracy: 0.7339\n",
      "Epoch 8/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6276 - accuracy: 0.7308\n",
      "Epoch 9/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6177 - accuracy: 0.7378\n",
      "Epoch 10/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6181 - accuracy: 0.7374\n",
      "Epoch 11/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6177 - accuracy: 0.7366\n",
      "Epoch 12/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6246 - accuracy: 0.7298\n",
      "Epoch 13/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.6190 - accuracy: 0.7351\n",
      "Epoch 14/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6128 - accuracy: 0.7369\n",
      "Epoch 15/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6127 - accuracy: 0.7390\n",
      "Epoch 16/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6111 - accuracy: 0.7370\n",
      "Epoch 17/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6195 - accuracy: 0.7346\n",
      "Epoch 18/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6129 - accuracy: 0.7392\n",
      "Epoch 19/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6136 - accuracy: 0.7362\n",
      "Epoch 20/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6130 - accuracy: 0.7362\n",
      "Epoch 21/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6080 - accuracy: 0.7402\n",
      "Epoch 22/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.6127 - accuracy: 0.7354\n",
      "Epoch 23/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.6140 - accuracy: 0.7377\n",
      "Epoch 24/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6204 - accuracy: 0.7329\n",
      "Epoch 25/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.6124 - accuracy: 0.7386\n",
      "Epoch 26/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.6106 - accuracy: 0.7392\n",
      "Epoch 27/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.6122 - accuracy: 0.7395\n",
      "Epoch 28/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6031 - accuracy: 0.7394\n",
      "Epoch 29/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6044 - accuracy: 0.7404\n",
      "Epoch 30/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6048 - accuracy: 0.7398\n",
      "Epoch 31/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6029 - accuracy: 0.7417\n",
      "Epoch 32/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6112 - accuracy: 0.7375\n",
      "Epoch 33/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6069 - accuracy: 0.7386\n",
      "Epoch 34/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.6036 - accuracy: 0.7430\n",
      "Epoch 35/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6013 - accuracy: 0.7391\n",
      "Epoch 36/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.6043 - accuracy: 0.7418\n",
      "Epoch 37/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6011 - accuracy: 0.7422\n",
      "Epoch 38/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.6001 - accuracy: 0.7442\n",
      "Epoch 39/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.5986 - accuracy: 0.7460\n",
      "Epoch 40/150\n",
      "125/125 [==============================] - 12s 97ms/step - loss: 0.5974 - accuracy: 0.7442\n",
      "Epoch 41/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.5920 - accuracy: 0.7442\n",
      "Epoch 42/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5962 - accuracy: 0.7474\n",
      "Epoch 43/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.6043 - accuracy: 0.7451\n",
      "Epoch 44/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5919 - accuracy: 0.7478\n",
      "Epoch 45/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5943 - accuracy: 0.7467\n",
      "Epoch 46/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5945 - accuracy: 0.7477\n",
      "Epoch 47/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5942 - accuracy: 0.7484\n",
      "Epoch 48/150\n",
      "125/125 [==============================] - 12s 96ms/step - loss: 0.6024 - accuracy: 0.7395\n",
      "Epoch 49/150\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 0.5962 - accuracy: 0.7438\n",
      "Epoch 50/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5912 - accuracy: 0.7478\n",
      "Epoch 51/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5952 - accuracy: 0.7465\n",
      "Epoch 52/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5916 - accuracy: 0.7467\n",
      "Epoch 53/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5877 - accuracy: 0.7485\n",
      "Epoch 54/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5910 - accuracy: 0.7473\n",
      "Epoch 55/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5869 - accuracy: 0.7505\n",
      "Epoch 56/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5912 - accuracy: 0.7468\n",
      "Epoch 57/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.6068 - accuracy: 0.7395\n",
      "Epoch 58/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5884 - accuracy: 0.7480\n",
      "Epoch 59/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5845 - accuracy: 0.7486\n",
      "Epoch 60/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5915 - accuracy: 0.7441\n",
      "Epoch 61/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5855 - accuracy: 0.7528\n",
      "Epoch 62/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5818 - accuracy: 0.7508\n",
      "Epoch 63/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5899 - accuracy: 0.7478\n",
      "Epoch 64/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5981 - accuracy: 0.7453\n",
      "Epoch 65/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5928 - accuracy: 0.7484\n",
      "Epoch 66/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5915 - accuracy: 0.7466\n",
      "Epoch 67/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5873 - accuracy: 0.7455\n",
      "Epoch 68/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5838 - accuracy: 0.7509\n",
      "Epoch 69/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5826 - accuracy: 0.7466\n",
      "Epoch 70/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5851 - accuracy: 0.7476\n",
      "Epoch 71/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.6079 - accuracy: 0.7373\n",
      "Epoch 72/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5842 - accuracy: 0.7509\n",
      "Epoch 73/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5795 - accuracy: 0.7488\n",
      "Epoch 74/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5780 - accuracy: 0.7522\n",
      "Epoch 75/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5832 - accuracy: 0.7485\n",
      "Epoch 76/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5737 - accuracy: 0.7561\n",
      "Epoch 77/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5870 - accuracy: 0.7458\n",
      "Epoch 78/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.5786 - accuracy: 0.7523\n",
      "Epoch 79/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5773 - accuracy: 0.7535\n",
      "Epoch 80/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5726 - accuracy: 0.7554\n",
      "Epoch 81/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5756 - accuracy: 0.7526\n",
      "Epoch 82/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5773 - accuracy: 0.7523\n",
      "Epoch 83/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5795 - accuracy: 0.7538\n",
      "Epoch 84/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5743 - accuracy: 0.7514\n",
      "Epoch 85/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5831 - accuracy: 0.7499\n",
      "Epoch 86/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5777 - accuracy: 0.7527\n",
      "Epoch 87/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5717 - accuracy: 0.7542\n",
      "Epoch 88/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5756 - accuracy: 0.7517\n",
      "Epoch 89/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5759 - accuracy: 0.7534\n",
      "Epoch 90/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5753 - accuracy: 0.7546\n",
      "Epoch 91/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5809 - accuracy: 0.7526\n",
      "Epoch 92/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5729 - accuracy: 0.7557\n",
      "Epoch 93/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5855 - accuracy: 0.7468\n",
      "Epoch 94/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5690 - accuracy: 0.7536\n",
      "Epoch 95/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5687 - accuracy: 0.7536\n",
      "Epoch 96/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5758 - accuracy: 0.7517\n",
      "Epoch 97/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5663 - accuracy: 0.7566\n",
      "Epoch 98/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5695 - accuracy: 0.7580\n",
      "Epoch 99/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5725 - accuracy: 0.7533\n",
      "Epoch 100/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.6292 - accuracy: 0.7352\n",
      "Epoch 101/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.6241 - accuracy: 0.7289\n",
      "Epoch 102/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5752 - accuracy: 0.7477\n",
      "Epoch 103/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5718 - accuracy: 0.7526\n",
      "Epoch 104/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5708 - accuracy: 0.7542\n",
      "Epoch 105/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5672 - accuracy: 0.7580\n",
      "Epoch 106/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5673 - accuracy: 0.7602\n",
      "Epoch 107/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5768 - accuracy: 0.7542\n",
      "Epoch 108/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5634 - accuracy: 0.7573\n",
      "Epoch 109/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5648 - accuracy: 0.7568\n",
      "Epoch 110/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5658 - accuracy: 0.7562\n",
      "Epoch 111/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5683 - accuracy: 0.7583\n",
      "Epoch 112/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5720 - accuracy: 0.7545\n",
      "Epoch 113/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5618 - accuracy: 0.7629\n",
      "Epoch 114/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5709 - accuracy: 0.7565\n",
      "Epoch 115/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5746 - accuracy: 0.7549\n",
      "Epoch 116/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5783 - accuracy: 0.7523\n",
      "Epoch 117/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5650 - accuracy: 0.7592\n",
      "Epoch 118/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5528 - accuracy: 0.7611\n",
      "Epoch 119/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5791 - accuracy: 0.7550\n",
      "Epoch 120/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5554 - accuracy: 0.7610\n",
      "Epoch 121/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5679 - accuracy: 0.7544\n",
      "Epoch 122/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5572 - accuracy: 0.7593\n",
      "Epoch 123/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5616 - accuracy: 0.7568\n",
      "Epoch 124/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5507 - accuracy: 0.7617\n",
      "Epoch 125/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5728 - accuracy: 0.7512\n",
      "Epoch 126/150\n",
      "125/125 [==============================] - 12s 99ms/step - loss: 0.5695 - accuracy: 0.7582\n",
      "Epoch 127/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.5561 - accuracy: 0.7613\n",
      "Epoch 128/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.5839 - accuracy: 0.7471\n",
      "Epoch 129/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5641 - accuracy: 0.7586\n",
      "Epoch 130/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5567 - accuracy: 0.7617\n",
      "Epoch 131/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5580 - accuracy: 0.7590\n",
      "Epoch 132/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5699 - accuracy: 0.7527\n",
      "Epoch 133/150\n",
      "125/125 [==============================] - 12s 98ms/step - loss: 0.5513 - accuracy: 0.7594\n",
      "Epoch 134/150\n",
      "125/125 [==============================] - 13s 100ms/step - loss: 0.5518 - accuracy: 0.7626\n",
      "Epoch 135/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5443 - accuracy: 0.7654\n",
      "Epoch 136/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5536 - accuracy: 0.7623\n",
      "Epoch 137/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5638 - accuracy: 0.7558\n",
      "Epoch 138/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5550 - accuracy: 0.7626\n",
      "Epoch 139/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5555 - accuracy: 0.7601\n",
      "Epoch 140/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5494 - accuracy: 0.7637\n",
      "Epoch 141/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5488 - accuracy: 0.7623\n",
      "Epoch 142/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5454 - accuracy: 0.7666\n",
      "Epoch 143/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5496 - accuracy: 0.7644\n",
      "Epoch 144/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5610 - accuracy: 0.7582\n",
      "Epoch 145/150\n",
      "125/125 [==============================] - 13s 101ms/step - loss: 0.5599 - accuracy: 0.7614\n",
      "Epoch 146/150\n",
      "125/125 [==============================] - 12s 100ms/step - loss: 0.5612 - accuracy: 0.7581\n",
      "Epoch 147/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5459 - accuracy: 0.7681\n",
      "Epoch 148/150\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 0.5547 - accuracy: 0.7602\n",
      "Epoch 149/150\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 0.5559 - accuracy: 0.7590\n",
      "Epoch 150/150\n",
      "125/125 [==============================] - 13s 102ms/step - loss: 0.5622 - accuracy: 0.7615\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x196ad606440>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.5269 - accuracy: 0.7742\n",
      "Epoch 2/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.5106 - accuracy: 0.7827\n",
      "Epoch 3/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.5051 - accuracy: 0.7846\n",
      "Epoch 4/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.5020 - accuracy: 0.7863\n",
      "Epoch 5/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.5013 - accuracy: 0.7847\n",
      "Epoch 6/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4989 - accuracy: 0.7874\n",
      "Epoch 7/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4968 - accuracy: 0.7900\n",
      "Epoch 8/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4968 - accuracy: 0.7883\n",
      "Epoch 9/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4952 - accuracy: 0.7883\n",
      "Epoch 10/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4945 - accuracy: 0.7909\n",
      "Epoch 11/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4964 - accuracy: 0.7896\n",
      "Epoch 12/150\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.4929 - accuracy: 0.7905\n",
      "Epoch 13/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4929 - accuracy: 0.7922\n",
      "Epoch 14/150\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4920 - accuracy: 0.7922\n",
      "Epoch 15/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4921 - accuracy: 0.7916\n",
      "Epoch 16/150\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4915 - accuracy: 0.7902\n",
      "Epoch 17/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4928 - accuracy: 0.7894\n",
      "Epoch 18/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4916 - accuracy: 0.7913\n",
      "Epoch 19/150\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4893 - accuracy: 0.7920\n",
      "Epoch 20/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4905 - accuracy: 0.7934\n",
      "Epoch 21/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4923 - accuracy: 0.7919\n",
      "Epoch 22/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4910 - accuracy: 0.7926\n",
      "Epoch 23/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4934 - accuracy: 0.7909\n",
      "Epoch 24/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4891 - accuracy: 0.7944\n",
      "Epoch 25/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4893 - accuracy: 0.7930\n",
      "Epoch 26/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4883 - accuracy: 0.7935\n",
      "Epoch 27/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4878 - accuracy: 0.7930\n",
      "Epoch 28/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4883 - accuracy: 0.7930\n",
      "Epoch 29/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4910 - accuracy: 0.7920\n",
      "Epoch 30/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4888 - accuracy: 0.7925\n",
      "Epoch 31/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4856 - accuracy: 0.7932\n",
      "Epoch 32/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4874 - accuracy: 0.7923\n",
      "Epoch 33/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4855 - accuracy: 0.7939\n",
      "Epoch 34/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4861 - accuracy: 0.7936\n",
      "Epoch 35/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4844 - accuracy: 0.7958\n",
      "Epoch 36/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4843 - accuracy: 0.7947\n",
      "Epoch 37/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4841 - accuracy: 0.7927\n",
      "Epoch 38/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4862 - accuracy: 0.7940\n",
      "Epoch 39/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4891 - accuracy: 0.7922\n",
      "Epoch 40/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4861 - accuracy: 0.7949\n",
      "Epoch 41/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4831 - accuracy: 0.7943\n",
      "Epoch 42/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4834 - accuracy: 0.7947\n",
      "Epoch 43/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4828 - accuracy: 0.7955\n",
      "Epoch 44/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4828 - accuracy: 0.7955\n",
      "Epoch 45/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4843 - accuracy: 0.7949\n",
      "Epoch 46/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4861 - accuracy: 0.7931\n",
      "Epoch 47/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4892 - accuracy: 0.7908\n",
      "Epoch 48/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4840 - accuracy: 0.7940\n",
      "Epoch 49/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4828 - accuracy: 0.7949\n",
      "Epoch 50/150\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.4823 - accuracy: 0.7942\n",
      "Epoch 51/150\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.4837 - accuracy: 0.7957\n",
      "Epoch 52/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4851 - accuracy: 0.7952\n",
      "Epoch 53/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4824 - accuracy: 0.7951\n",
      "Epoch 54/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4806 - accuracy: 0.7979\n",
      "Epoch 55/150\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.4789 - accuracy: 0.7961\n",
      "Epoch 56/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4793 - accuracy: 0.7980\n",
      "Epoch 57/150\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4783 - accuracy: 0.7985\n",
      "Epoch 58/150\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4784 - accuracy: 0.7974\n",
      "Epoch 59/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4781 - accuracy: 0.7993\n",
      "Epoch 60/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4770 - accuracy: 0.7974\n",
      "Epoch 61/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4774 - accuracy: 0.7986\n",
      "Epoch 62/150\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4758 - accuracy: 0.7986\n",
      "Epoch 63/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4754 - accuracy: 0.7992\n",
      "Epoch 64/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4758 - accuracy: 0.7982\n",
      "Epoch 65/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4784 - accuracy: 0.7967\n",
      "Epoch 66/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4788 - accuracy: 0.7952\n",
      "Epoch 67/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4782 - accuracy: 0.7963\n",
      "Epoch 68/150\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4769 - accuracy: 0.7989\n",
      "Epoch 69/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4769 - accuracy: 0.7986\n",
      "Epoch 70/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4780 - accuracy: 0.7987\n",
      "Epoch 71/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4766 - accuracy: 0.7983\n",
      "Epoch 72/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4754 - accuracy: 0.7980\n",
      "Epoch 73/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4753 - accuracy: 0.7980\n",
      "Epoch 74/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4742 - accuracy: 0.8014\n",
      "Epoch 75/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4760 - accuracy: 0.8009\n",
      "Epoch 76/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4751 - accuracy: 0.7987\n",
      "Epoch 77/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4759 - accuracy: 0.7996\n",
      "Epoch 78/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4751 - accuracy: 0.7998\n",
      "Epoch 79/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4751 - accuracy: 0.7996\n",
      "Epoch 80/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4746 - accuracy: 0.7988\n",
      "Epoch 81/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4716 - accuracy: 0.8029\n",
      "Epoch 82/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4729 - accuracy: 0.8014\n",
      "Epoch 83/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4757 - accuracy: 0.7980\n",
      "Epoch 84/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4801 - accuracy: 0.7959\n",
      "Epoch 85/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4848 - accuracy: 0.7946\n",
      "Epoch 86/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4740 - accuracy: 0.8001\n",
      "Epoch 87/150\n",
      "13/13 [==============================] - 1s 99ms/step - loss: 0.4710 - accuracy: 0.8016\n",
      "Epoch 88/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4688 - accuracy: 0.8026\n",
      "Epoch 89/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4697 - accuracy: 0.8027\n",
      "Epoch 90/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4698 - accuracy: 0.8020\n",
      "Epoch 91/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4756 - accuracy: 0.7992\n",
      "Epoch 92/150\n",
      "13/13 [==============================] - 1s 99ms/step - loss: 0.4714 - accuracy: 0.8011\n",
      "Epoch 93/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4707 - accuracy: 0.8021\n",
      "Epoch 94/150\n",
      "13/13 [==============================] - 1s 99ms/step - loss: 0.4702 - accuracy: 0.8029\n",
      "Epoch 95/150\n",
      "13/13 [==============================] - 1s 99ms/step - loss: 0.4764 - accuracy: 0.7990\n",
      "Epoch 96/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4757 - accuracy: 0.7979\n",
      "Epoch 97/150\n",
      "13/13 [==============================] - 1s 100ms/step - loss: 0.4692 - accuracy: 0.8020\n",
      "Epoch 98/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4698 - accuracy: 0.8014\n",
      "Epoch 99/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4725 - accuracy: 0.8001\n",
      "Epoch 100/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4712 - accuracy: 0.8018\n",
      "Epoch 101/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4717 - accuracy: 0.8011\n",
      "Epoch 102/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4747 - accuracy: 0.8001\n",
      "Epoch 103/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4685 - accuracy: 0.8034\n",
      "Epoch 104/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4658 - accuracy: 0.8022\n",
      "Epoch 105/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4649 - accuracy: 0.8046\n",
      "Epoch 106/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4678 - accuracy: 0.8022\n",
      "Epoch 107/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4669 - accuracy: 0.8040\n",
      "Epoch 108/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4655 - accuracy: 0.8035\n",
      "Epoch 109/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4656 - accuracy: 0.8032\n",
      "Epoch 110/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4669 - accuracy: 0.8034\n",
      "Epoch 111/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4695 - accuracy: 0.8027\n",
      "Epoch 112/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4737 - accuracy: 0.7976\n",
      "Epoch 113/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4735 - accuracy: 0.7990\n",
      "Epoch 114/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4679 - accuracy: 0.8015\n",
      "Epoch 115/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4675 - accuracy: 0.8020\n",
      "Epoch 116/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4720 - accuracy: 0.8001\n",
      "Epoch 117/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4678 - accuracy: 0.8029\n",
      "Epoch 118/150\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4670 - accuracy: 0.8040\n",
      "Epoch 119/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4667 - accuracy: 0.8028\n",
      "Epoch 120/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4638 - accuracy: 0.8042\n",
      "Epoch 121/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4684 - accuracy: 0.8013\n",
      "Epoch 122/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4651 - accuracy: 0.8036\n",
      "Epoch 123/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4666 - accuracy: 0.8024\n",
      "Epoch 124/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4607 - accuracy: 0.8060\n",
      "Epoch 125/150\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.4644 - accuracy: 0.8045\n",
      "Epoch 126/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4672 - accuracy: 0.8018\n",
      "Epoch 127/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4739 - accuracy: 0.7995\n",
      "Epoch 128/150\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.4717 - accuracy: 0.7995\n",
      "Epoch 129/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4656 - accuracy: 0.8028\n",
      "Epoch 130/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4653 - accuracy: 0.8014\n",
      "Epoch 131/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4608 - accuracy: 0.8080\n",
      "Epoch 132/150\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4603 - accuracy: 0.8052\n",
      "Epoch 133/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4608 - accuracy: 0.8050\n",
      "Epoch 134/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4628 - accuracy: 0.8032\n",
      "Epoch 135/150\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4634 - accuracy: 0.8026\n",
      "Epoch 136/150\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4595 - accuracy: 0.8046\n",
      "Epoch 137/150\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4623 - accuracy: 0.8044\n",
      "Epoch 138/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4692 - accuracy: 0.8017\n",
      "Epoch 139/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4658 - accuracy: 0.8006\n",
      "Epoch 140/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4593 - accuracy: 0.8056\n",
      "Epoch 141/150\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4576 - accuracy: 0.8062\n",
      "Epoch 142/150\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4604 - accuracy: 0.8066\n",
      "Epoch 143/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4590 - accuracy: 0.8044\n",
      "Epoch 144/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4571 - accuracy: 0.8076\n",
      "Epoch 145/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4541 - accuracy: 0.8090\n",
      "Epoch 146/150\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4563 - accuracy: 0.8072\n",
      "Epoch 147/150\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4635 - accuracy: 0.8039\n",
      "Epoch 148/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4671 - accuracy: 0.8024\n",
      "Epoch 149/150\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.4632 - accuracy: 0.8014\n",
      "Epoch 150/150\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4621 - accuracy: 0.8023\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x197b9a39a50>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=150, batch_size=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 8s 41ms/step - loss: 0.8036 - accuracy: 0.7171\n",
      "[0.8036181330680847, 0.7170946002006531]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "X_test = np.array(X_test)\n",
    "accuracy = model.evaluate(X_test, Y_test)\n",
    "print(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_0.8_0.72\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/model_0.8_0.72')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/model_0.8_0.72')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}