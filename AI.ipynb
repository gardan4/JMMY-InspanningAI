{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin hier\n",
    "Begin met het runnen van deze blokken code.  \n",
    "Deze zijn verantwoordelijk voor imports, setup, dependencies en andere zaken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import install_deps as deps\n",
    "choiche = input(\"Install Deps? (choose y to continue) \")\n",
    "if choiche == \"y\":\n",
    "    deps.unattended_install()\n",
    "else:\n",
    "    pass\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import data_generator as dgen\n",
    "\n",
    "print(\"Succes loading Imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def get_file_name(path):\n",
    "    file_name = path[path.rfind('/') + 1:]\n",
    "    # Splits out the file-type designation\n",
    "    file_name, file_extension = file_name.split('.')\n",
    "    return file_name\n",
    "    \n",
    "print(\"Succes loading Functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heb je al data?\n",
    "Als er al trainingsdata bestaat, schrijf dan simpelweg de filename bij het betreffende blok.  \n",
    "Run anders het blok waarin de data nog word gegenereerd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Ik heb geen data\"\"\"\n",
    "# Start here if no data has been generated.\n",
    "\n",
    "print(\"Provide the path to a video file.\\n\"\n",
    "      \"  (Example: C:/Users/admin/video/video.mp4)\")\n",
    "\n",
    "vid_path = input(\"Provide a video path: \")\n",
    "\n",
    "try:\n",
    "      vid_name = get_file_name(vid_path)\n",
    "      print(f\"Provided path: '{vid_path}',\\nfound filename: '{vid_name}'\")\n",
    "      print(\"\")\n",
    "except Exception as e:\n",
    "      print(f\"Something went wrong, did you not provide a path?\\n{e}\")\n",
    "\n",
    "try:\n",
    "      generator = dgen.Generator(vid_path)\n",
    "      generator.generate_data()\n",
    "      print(f\"Video has been processed and exported to {generator.file_name}__trainingsData.mp4\")\n",
    "      print(f\"Data generated and exported to {generator.file_name}_trainingsData.json\")\n",
    "      print(\"\")\n",
    "except Exception as e:\n",
    "      print(f\"Something went wrong, any generated data can be dismissed.\\n{e}\")\n",
    "\n",
    "try: \n",
    "      data_path = f\"generateData_OUTPUT/{vid_name}_trainingsData.json\"\n",
    "      frame_data = pd.read_json(data_path, orient='index')\n",
    "except Exception as e:\n",
    "      print(f\"Something went wrong.\\n {e}\")\n",
    "\n",
    "\n",
    "print(\"The data-table was loaded. \\nTotal Table size: \")\n",
    "print(f\"Rows: {frame_data.shape[0]}, Columns: {frame_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Ik heb al trainingsdata. \"\"\"\n",
    "# Start here if data has already been generated.\n",
    "print(\"Provide the filename to a file in \"\n",
    "      \"the generateData_OUTPUT folder.\\n\"\n",
    "      \"Example: perfect_example_trainingsData\")\n",
    "\n",
    "try:\n",
    "      data_path = input(\"Filename: \")\n",
    "      vid_name = get_file_name(data_path)\n",
    "      data_path = f\"generateData_OUTPUT/{vid_name}.json\"\n",
    "      print(f\"Provided path: {data_path}\")\n",
    "except Exception as e:\n",
    "      print(f\"Something went wrong, did you not provide a path?\\n{e}\")\n",
    "\n",
    "try: \n",
    "      frame_data = pd.read_json(data_path, orient='index')\n",
    "except Exception as e:\n",
    "      print(f\"Something went wrong.\\n {e}\")\n",
    "\n",
    "print(\"\\nTotal Table size: \")\n",
    "print(f\"Rows: {frame_data.shape[0]}, Columns: {frame_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cycle_data = pd.read_csv(\"dataset bike/220316_1023_JOS.csv\", sep=\";\")\n",
    "# cycle_data.head()\n",
    "#\n",
    "# maxhr = max(cycle_data[\"idHeartrate\"])\n",
    "# cycle_data['heartRateZone'] = cycle_data.apply(\n",
    "#     lambda row: 5 if (row.idHeartrate > (maxhr * 0.9)) else (\n",
    "#         4 if (row.idHeartrate > (maxhr * 0.8)) else (\n",
    "#             3 if (row.idHeartrate > (maxhr * 0.7)) else (\n",
    "#                 2 if (row.idHeartrate > (maxhr * 0.6)) else (\n",
    "#                     1 if (row.idHeartrate > (maxhr * 0.5)) else (0))))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frame_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = frame_data.drop(columns=['TS', 'HR', 'PWR', 'heartRateZone'])\n",
    "Y = frame_data[\"heartRateZone\"]\n",
    "\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, Input, Concatenate, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputTensor = Input(shape=(1434,))\n",
    "layers = []\n",
    "\n",
    "for i in range(0, 1431, 3):\n",
    "    layers.append(Lambda(lambda x: x[:,i: i+3], output_shape=((3,)))(inputTensor))\n",
    "for i in range(0, 477):\n",
    "    layers[i] = Dense(1)(layers[i])\n",
    "coordslayer = Concatenate()(layers)\n",
    "\n",
    "hidden1 = Dense(477*2, activation='relu')(coordslayer)\n",
    "hidden2 = Dense(477, activation='relu')(hidden1)\n",
    "hidden3 = Dense(240, activation='relu')(hidden2)\n",
    "hidden4 = Dense(100, activation='relu')(hidden3)\n",
    "hidden5 = Dense(20, activation='relu')(hidden4)\n",
    "\n",
    "outputTensor = Dense(5, activation='sigmoid')(hidden5)\n",
    "model = Model(inputs=inputTensor, outputs=outputTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, Y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([[0,00,000], [1,11,111], [2,22,222], [3,33,333]])\n",
    "print(x[:,:])\n",
    "print(x[:,0:3])\n",
    "g = lambda g: g[:,2:4]\n",
    "print(g(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
